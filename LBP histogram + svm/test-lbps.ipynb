{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14053596,"sourceType":"datasetVersion","datasetId":8945667}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nfrom skimage.feature import local_binary_pattern\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nfrom tqdm import tqdm \nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:31:59.746148Z","iopub.execute_input":"2025-12-13T01:31:59.746372Z","iopub.status.idle":"2025-12-13T01:32:02.315155Z","shell.execute_reply.started":"2025-12-13T01:31:59.746351Z","shell.execute_reply":"2025-12-13T01:32:02.313620Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def get_lbp(img_path, radius=1, n_points=8, method='ror'):\n    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    image=cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n    lbp = local_binary_pattern(image, P=n_points, R=radius, method=method)\n    return lbp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:33:45.674091Z","iopub.execute_input":"2025-12-13T01:33:45.674444Z","iopub.status.idle":"2025-12-13T01:33:45.682707Z","shell.execute_reply.started":"2025-12-13T01:33:45.674419Z","shell.execute_reply":"2025-12-13T01:33:45.681027Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"method uniform","metadata":{}},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom skimage.feature import local_binary_pattern\n\ndef get_lbp(img_path, grid_size=9, target_size=224):\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, (target_size, target_size))\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    \n    # Tính LBP\n    lbp = local_binary_pattern(gray, P=8, R=1, method='uniform')\n    \n    h, w = lbp.shape\n    bin_h = h // grid_size\n    bin_w = w // grid_size\n    \n    features = []\n    for i in range(grid_size):\n        for j in range(grid_size):\n            # Lấy ô con\n            patch = lbp[i*bin_h:(i+1)*bin_h, j*bin_w:(j+1)*bin_w]\n            # Tính histogram cho ô này\n            hist, _ = np.histogram(patch.ravel(), bins=10, range=(0, 10), density=True)\n            features.append(hist)\n    \n    return np.concatenate(features)  # shape: (grid_size*grid_size*10,)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:33:47.589852Z","iopub.execute_input":"2025-12-13T01:33:47.590692Z","iopub.status.idle":"2025-12-13T01:33:47.598788Z","shell.execute_reply.started":"2025-12-13T01:33:47.590658Z","shell.execute_reply":"2025-12-13T01:33:47.597584Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"BASE_PATH = \"/kaggle/input/hath-food/food dataset/Images\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:33:52.130897Z","iopub.execute_input":"2025-12-13T01:33:52.131423Z","iopub.status.idle":"2025-12-13T01:33:52.136076Z","shell.execute_reply.started":"2025-12-13T01:33:52.131397Z","shell.execute_reply":"2025-12-13T01:33:52.134922Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_dataset(root_path, subset=\"train\"):\n\n    data = []\n    labels = []\n    \n    path = os.path.join(root_path, subset)\n    if not os.path.exists(path):\n        print(f\"error in finding {path}\")\n        return np.array([]), np.array([])\n\n    print(f\"loading {subset}...\")\n    \n    classes = os.listdir(path)\n    \n    for class_name in classes:\n        class_dir = os.path.join(path, class_name)\n        if not os.path.isdir(class_dir):\n            continue\n            \n      \n        files = os.listdir(class_dir)\n        for file in tqdm(files, desc=class_name, leave=False):\n            image_path = os.path.join(class_dir, file)\n            \n            hist = get_lbp(image_path)\n            \n            if hist is not None:\n                data.append(hist)\n                labels.append(class_name)\n                \n    return np.array(data), np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:33:53.593134Z","iopub.execute_input":"2025-12-13T01:33:53.593461Z","iopub.status.idle":"2025-12-13T01:33:53.601563Z","shell.execute_reply.started":"2025-12-13T01:33:53.593438Z","shell.execute_reply":"2025-12-13T01:33:53.599851Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X_train, y_train_text = load_dataset(BASE_PATH, \"train\")\nX_test, y_test_text = load_dataset(BASE_PATH, \"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:33:56.131100Z","iopub.execute_input":"2025-12-13T01:33:56.131414Z","iopub.status.idle":"2025-12-13T01:51:06.474380Z","shell.execute_reply.started":"2025-12-13T01:33:56.131392Z","shell.execute_reply":"2025-12-13T01:51:06.473246Z"}},"outputs":[{"name":"stdout","text":"loading train...\n","output_type":"stream"},{"name":"stderr","text":"Goi cuon:  50%|████▉     | 297/598 [00:12<00:15, 19.12it/s]        Corrupt JPEG data: 229 extraneous bytes before marker 0xd9\nNem chua:  22%|██▏       | 84/379 [00:03<00:17, 17.20it/s]  Corrupt JPEG data: 9 extraneous bytes before marker 0xe2\n                                                                  \r","output_type":"stream"},{"name":"stdout","text":"loading test...\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"le = LabelEncoder()\ny_train = le.fit_transform(y_train_text)\ny_test = le.transform(y_test_text) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:51:06.522788Z","iopub.execute_input":"2025-12-13T01:51:06.523233Z","iopub.status.idle":"2025-12-13T01:51:06.538620Z","shell.execute_reply.started":"2025-12-13T01:51:06.523204Z","shell.execute_reply":"2025-12-13T01:51:06.537463Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = SVC(kernel='rbf', C=10.0, gamma='scale', random_state=42, cache_size=100)\nmodel.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:51:06.539900Z","iopub.execute_input":"2025-12-13T01:51:06.540322Z","iopub.status.idle":"2025-12-13T01:54:14.170202Z","shell.execute_reply.started":"2025-12-13T01:51:06.540291Z","shell.execute_reply":"2025-12-13T01:54:14.169206Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"SVC(C=10.0, cache_size=100, random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10.0, cache_size=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10.0, cache_size=100, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"y_pred = model.predict(X_test)\n\nacc = accuracy_score(y_test, y_pred)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:54:14.171064Z","iopub.execute_input":"2025-12-13T01:54:14.171301Z","iopub.status.idle":"2025-12-13T01:55:47.156145Z","shell.execute_reply.started":"2025-12-13T01:54:14.171281Z","shell.execute_reply":"2025-12-13T01:55:47.155035Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T11:50:12.083949Z","iopub.execute_input":"2025-12-12T11:50:12.085474Z","iopub.status.idle":"2025-12-12T11:50:12.094009Z","shell.execute_reply.started":"2025-12-12T11:50:12.085433Z","shell.execute_reply":"2025-12-12T11:50:12.092644Z"}},"outputs":[{"name":"stdout","text":"0.1876984126984127\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nimport numpy as np\nprint(\"Độ chính xác (và các metric) theo từng lớp:\")\nprint(classification_report(y_test, y_pred, target_names=le.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T01:55:47.157368Z","iopub.execute_input":"2025-12-13T01:55:47.158616Z","iopub.status.idle":"2025-12-13T01:55:47.185525Z","shell.execute_reply.started":"2025-12-13T01:55:47.158584Z","shell.execute_reply":"2025-12-13T01:55:47.184671Z"}},"outputs":[{"name":"stdout","text":"Độ chính xác (và các metric) theo từng lớp:\n                  precision    recall  f1-score   support\n\n        Banh beo       0.19      0.18      0.19       129\n    Banh bot loc       0.12      0.10      0.11       144\n        Banh can       0.13      0.13      0.13       149\n       Banh canh       0.15      0.17      0.16       193\n      Banh chung       0.21      0.21      0.21       102\n       Banh cuon       0.13      0.18      0.15       228\n        Banh duc       0.05      0.03      0.04       133\n        Banh gio       0.19      0.20      0.20       129\n       Banh khot       0.15      0.16      0.15       167\n         Banh mi       0.26      0.36      0.30       268\n        Banh pia       0.15      0.15      0.15        89\n        Banh tet       0.15      0.15      0.15       138\nBanh trang nuong       0.20      0.19      0.20       159\n        Banh xeo       0.18      0.20      0.19       235\n      Bun bo Hue       0.17      0.26      0.21       306\n Bun dau mam tom       0.19      0.32      0.24       184\n         Bun mam       0.11      0.08      0.09       155\n        Bun rieu       0.18      0.16      0.17       231\n  Bun thit nuong       0.09      0.06      0.07       150\n       Ca kho to       0.29      0.25      0.27       136\n       Canh chua       0.21      0.19      0.20       165\n         Cao lau       0.12      0.07      0.09       124\n       Chao long       0.14      0.13      0.14       215\n         Com tam       0.20      0.18      0.19       189\n        Goi cuon       0.12      0.12      0.12       172\n         Hu tieu       0.16      0.14      0.15       197\n        Mi quang       0.23      0.17      0.19       177\n        Nem chua       0.08      0.04      0.05       109\n             Pho       0.23      0.15      0.18       162\n         Xoi xeo       0.22      0.19      0.20       105\n\n        accuracy                           0.17      5040\n       macro avg       0.17      0.16      0.16      5040\n    weighted avg       0.17      0.17      0.17      5040\n\n","output_type":"stream"}],"execution_count":13}]}